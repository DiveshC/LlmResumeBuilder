{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3.11 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /opt/homebrew/lib/python3.11/site-packages (0.10.44)\n",
      "Requirement already satisfied: llama-cpp-python in /opt/homebrew/lib/python3.11/site-packages (0.2.78)\n",
      "Requirement already satisfied: fpdf in /opt/homebrew/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.2.7)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-core==0.10.44 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.10.44)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.1.10)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.1.22)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.1.23)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /opt/homebrew/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/homebrew/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.44->llama-index) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (0.6.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (2023.12.2)\n",
      "Requirement already satisfied: httpx in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (0.25.2)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/diveshchudasama/Library/Python/3.11/lib/python/site-packages (from llama-index-core==0.10.44->llama-index) (1.5.8)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (1.26.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (1.33.0)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (2.1.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (10.1.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (0.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core==0.10.44->llama-index) (1.16.0)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /opt/homebrew/lib/python3.11/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /opt/homebrew/lib/python3.11/site-packages (from llama-cpp-python) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /opt/homebrew/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.44->llama-index) (2.5.2)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.44->llama-index) (3.7.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.44->llama-index) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.44->llama-index) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/homebrew/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.44->llama-index) (3.6)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.44->llama-index) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.44->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.44->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.44->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.44->llama-index) (2023.10.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core==0.10.44->llama-index) (1.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core==0.10.44->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core==0.10.44->llama-index) (2.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/homebrew/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.44->llama-index) (3.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.44->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json->llama-index-core==0.10.44->llama-index) (3.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/diveshchudasama/Library/Python/3.11/lib/python/site-packages (from pandas->llama-index-core==0.10.44->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->llama-index-core==0.10.44->llama-index) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->llama-index-core==0.10.44->llama-index) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/diveshchudasama/Library/Python/3.11/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.44->llama-index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.44->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.44->llama-index) (2.14.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/diveshchudasama/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.44->llama-index) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3.11 install llama-index llama-cpp-python fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LlamaCPP' from 'llama_index.llms' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaCPP\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     messages_to_prompt,\n\u001b[1;32m      4\u001b[0m     completion_to_prompt,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfpdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FPDF\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LlamaCPP' from 'llama_index.llms' (unknown location)"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.llama_utils import (\n",
    "    messages_to_prompt,\n",
    "    completion_to_prompt,\n",
    ")\n",
    "\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = 'llama-2-7b-chat.Q3_K_M.gguf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL \n",
    "llm = LlamaCPP(\n",
    "    # You can pass in the URL to a GGML model to download it automatically\n",
    "    model_path=model_url,\n",
    "    # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "    # model_url=None,\n",
    "    temperature=0.1,\n",
    "    # max_new_tokens=256,\n",
    "    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "    # context_window=4096,\n",
    "    # kwargs to pass to __call__()\n",
    "    generate_kwargs={},\n",
    "    # kwargs to pass to __init__()\n",
    "    # set to at least 1 to use GPU\n",
    "    # model_kwargs={\"n_gpu_layers\": 1},\n",
    "    # transform inputs into Llama2 format\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# llm = LlamaCPP(\n",
    "#         model_url=\"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q3_K_M.gguf\",\n",
    "#         model_path=None,\n",
    "#         temperature=0,\n",
    "#         max_new_tokens=512,\n",
    "#         context_window=10000,\n",
    "#         generate_kwargs={},\n",
    "#         verbose=True,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt ='''\n",
    "Rewrite the user's accomplishment for a resume in the following format with full sentences. \n",
    "\n",
    "I accomplished X by the measure Y that resulted in Z\n",
    "\n",
    "\n",
    "accomplishment: {}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_experience = '''\n",
    "    As a Junior Developer at Norconsult, I've played a key role in enhancing our business intelligence app, implementing diverse visualizations using CraftJS, ChartJS, Leaflet, and React libraries. I improved data accessibility by designing a system to access various sources and storing data in PostgreSQL. Strengthening data analysis capabilities, I utilized CubeJS for querying, measures, and dimensions. Additionally, I developed a robust REST API using Node.js, Express, middleware, and Winston to enhance application functionality and reliability. I also contributed to AI and machine learning advancements through research and prototyping.\n",
    "\n",
    "    My recent project, the Heads-Up Display Smart Helmet, received the \"Best Safety Analysis\" award, showcasing my innovation. I developed and tested it using Raspberry Pi 4 and Pi Camera for real-time video stream processing. Implementing object detection using TensorFlow lite models, I optimized performance with a transition from Python to C++. Demonstrating expertise in embedded systems design, I addressed task management through multiprocessing and multithreading.\n",
    "'''\n",
    "accomplishment=input(\"what did u achieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_question = prompt.join((accomplishment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_iter = llm.stream_complete(final_question)\n",
    "str_res = \"\"\n",
    "for response in response_iter:\n",
    "    str_res += response.delta\n",
    "    print(response.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def text_to_pdf(text, filename):\n",
    "    a4_width_mm = 210\n",
    "    pt_to_mm = 0.35\n",
    "    fontsize_pt = 10\n",
    "    fontsize_mm = fontsize_pt * pt_to_mm\n",
    "    margin_bottom_mm = 10\n",
    "    character_width_mm = 7 * pt_to_mm\n",
    "    width_text = a4_width_mm / character_width_mm\n",
    "\n",
    "    pdf = FPDF(orientation='P', unit='mm', format='A4')\n",
    "    pdf.set_auto_page_break(True, margin=margin_bottom_mm)\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(family='Arial', size=fontsize_pt)\n",
    "    splitted = text.split('\\n')\n",
    "\n",
    "    for line in splitted:\n",
    "        lines = textwrap.wrap(line, width_text)\n",
    "\n",
    "        if len(lines) == 0:\n",
    "            pdf.ln()\n",
    "\n",
    "        for wrap in lines:\n",
    "            pdf.cell(0, fontsize_mm, wrap, ln=1)\n",
    "\n",
    "    pdf.output(filename, 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str_res)\n",
    "# save FPDF() class into a \n",
    "# variable pdf\n",
    "pdf = FPDF()\n",
    "\n",
    "text_to_pdf(str_res, \"resume.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
